{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 双向循环神经网络\n",
    "在序列学习中，我们总是根据过去的序列$(\\mathbf{X}_1, \\ldots , \\mathbf{X}_{t-1})$去预测$\\mathbf{X}_{t}$，但是这并不是唯一的情况，在完形填空中，我们需要对上下文进行检索，从而完成结合上下文的词语预测。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隐马尔科夫模型中的DP\n",
    "\n",
    "如果想用概率图模型来解决序列预测的问题，可以设计一个隐变量模型：在任意时间步$t$，假设存在某个隐变量$h_t$，通过概率$P(x_t \\mid h_t)$来控制我们观测到的$x_t$，此外，任何$h_t \\to h_{t+1}$转移都是有一些状态转移概率$P(h_{t+1} \\mid h_t)$ 给出。这个概率图模型就是一个隐马尔可夫模型。\n",
    "\n",
    "因此，对于有$T$个观测值的序列，我们在观测状态和隐状态上具有以下联合概率分布：\n",
    "$$P(x_1,\\ldots,x_T,h_1,\\ldots,h_T) = \\prod_{t=1}^T P(h_t \\mid h_{t-1})P(x_t \\mid h_t), \\text{where} P(h_1|h_0)=P(h_1)$$\n",
    "\n",
    "假设我们观测到了所有的$x_i$除了$x_j$，并且我们的目标是计算$P(x_j \\mid x_{-j})$，其中$x_{-j}=(x_1, \\ldots, x_{j-1},x_{j+1},\\ldots,x_T)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
